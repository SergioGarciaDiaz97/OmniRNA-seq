# ğŸ§¬ OmniRNA-seq: High-Performance HPC Transcriptomics Pipeline

OmniRNA-seq es un ecosistema bioinformÃ¡tico integral para el anÃ¡lisis automatizado y reproducible de datos de RNAâ€‘seq *bulk* en entornos HPC. Transforma lecturas crudas de secuenciaciÃ³n en resultados biolÃ³gicos interpretables y listos para publicaciÃ³n, desacoplando la **ingenierÃ­a de datos** (Python) del **modelado estadÃ­stico avanzado** (R/Bioconductor) y del **despliegue reproducible** basado en contenedores **Apptainer/Singularity**.

El sistema es agnÃ³stico al organismo, con soporte nativo y flujos de anotaciÃ³n validados para:
**Homo sapiens**, **Mus musculus**, **Saccharomyces cerevisiae**, **Arabidopsis thaliana**, **Danio rerio**, **C. elegans** y **Drosophila melanogaster**.

---

## ğŸ“š Ãndice
1. [OrganizaciÃ³n del Proyecto](#-1-organizaciÃ³n-del-proyecto-separation-of-concerns)  
2. [Modos de EjecuciÃ³n](#-2-modos-de-ejecuciÃ³n-orquestaciÃ³n-inteligente)  
3. [Launcher Maestro](#-3-punto-de-entrada-launcher-maestro-rna_seq_lets_trysh)  
4. [Dependencias y Contenedores](#-4-dependencias-y-entorno-de-ejecuciÃ³n-contenedores)  
5. [Centro de ConfiguraciÃ³n JSON](#-5-centro-de-control-de-configuraciÃ³n-json)  
6. [Requisitos de Metadatos](#-6-requisitos-de-metadatos-metadata_archivos)  
7. [Arquitectura del Sistema](#-7-arquitectura-del-sistema)  
8. [Estructura Global de Resultados](#-8-estructura-global-de-resultados-output-tree)  
9. [AutorÃ­a y Colaboraciones](#-9-autorÃ­a-impacto-y-colaboraciÃ³n)

---

## ğŸ“‚ 1. OrganizaciÃ³n del Proyecto (Separation of Concerns)

```text
OmniRNA-seq/
â”œâ”€â”€ RNA_SEQ_LETS_TRY.sh        # Launcher maestro (HPC / SLURM)
â”œâ”€â”€ JSON/                      # ConfiguraciÃ³n del experimento (El Contrato)
â”‚   â”œâ”€â”€ project01.json
â”‚   â””â”€â”€ project02.json
â”‚   â””â”€â”€ ...
â”‚ 
â”œâ”€â”€ Metadata_Archivos/         # Archivos CSV de diseÃ±o experimental
â”‚   â”œâ”€â”€ metadata_project01.csv
â”‚   â””â”€â”€ metadata_project02.csv
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ src/
â”‚   â””â”€â”€ PYTHON_CODES/          # OrquestaciÃ³n
â”‚       â”œâ”€â”€ main.py
â”‚       â”œâ”€â”€ experiment_profiler.py
â”‚       â”œâ”€â”€ data_conector.py
â”‚       â””â”€â”€ 01_pipeline_core.py
â”‚
â”œâ”€â”€ R_CODES/                   # Motor EstadÃ­stico y BiolÃ³gico
â”‚   â”œâ”€â”€ 01_EDA_QC.R
â”‚   â”œâ”€â”€ 02_Differential_expression.R
â”‚   â”œâ”€â”€ 03_Functional_analysis_viz.R
â”‚   â””â”€â”€ 04_Comprehensive_Report_Builder.R
â”‚
â””â”€â”€ logs/                      # Trazas de ejecuciÃ³n SLURM
```
**Flujo lÃ³gico:**  
`Launcher â†’ Python (data engineering) â†’ R (estadÃ­stica/biolÃ³gica) â†’ PDFs publicables`

---

## ğŸš€ 2. Modos de EjecuciÃ³n (OrquestaciÃ³n Inteligente)

El pipeline implementa una lÃ³gica de decisiÃ³n automatizada para determinar el flujo de trabajo Ã³ptimo. Esta decisiÃ³n se basa en la fuente de los datos (**pÃºblicos vs. locales**) y el formato de entrada (**crudos vs. matriz**).

Existen los parÃ¡metros `cleanup_only_fastq` y `retain_only_fastqc_and_bam` (ver apartado [5. ConfiguraciÃ³n JSON](#-5-centro-de-control-de-configuraciÃ³n-json)) para ahorrar espacio de almacenamiento.

<details>
<summary>$\Large \color{#8B0000}{\textbf{2.1. ğŸŒ Modo Explorer (RecuperaciÃ³n Automatizada)}}$</summary>
<br>

<div style="background-color: #fff3cd; border-left: 4px solid #ffc107; padding: 12px; margin: 10px 0; border-radius: 4px;">
<span style="font-size: 1.2em;">ğŸ’¡</span> 
<span style="font-weight: bold; color: #856404;"><b>Ideal para: </b></span> Meta-anÃ¡lisis y benchmarking utilizando datos de <b>GEO, ENA o SRA</b>.<br>
<span style="font-weight: bold; color: #856404;">ActivaciÃ³n:</span> Requiere suministrar un <b>Project_ID</b> (ej. PRJNA, SRP) como argumento.
</div>

### $\color{#8B0000}{\text{Flujo Completo (End-to-End Processing):}}$
- **ConfiguraciÃ³n:** `"counting_method": "featurecounts"`.
- **DescripciÃ³n:** Interroga las APIs de ENA/SRA para recuperar automÃ¡ticamente metadatos y FASTQs. Ejecuta el pipeline integral: QC, alineamiento y cuantificaciÃ³n.

### $\color{#8B0000}{\text{Flujo Acelerado (Direct Matrix Analysis - Public):}}$
- **ConfiguraciÃ³n:** `"counting_method": "precomputed_csv" + URL remota`.
- **DescripciÃ³n:** Descarga la matriz de conteos directamente del autor, omitiendo el alineamiento para saltar al anÃ¡lisis estadÃ­stico y funcional.

**Sintaxis (Bash):**
```bash
sbatch RNA_SEQ_LETS_TRY.sh JSON/config.json PRJNAxxxx
```
</details> 

<details>
<summary>$\Large \color{#8B0000}{\textbf{2.2. ğŸ’» Modo Local (Infraestructura Privada / On-Premise)}}$</summary>
<br>

<div style="background-color: #fff3cd; border-left: 4px solid #ffc107; padding: 12px; margin: 10px 0; border-radius: 4px;">
<span style="font-size: 1.2em;">ğŸ’¡</span> 
<span style="font-weight: bold; color: #856404;"><b>Ideal para: </b></span> AnÃ¡lisis de datos propios del laboratorio o colaboraciones privadas, sin conexiÃ³n a APIs externas.<br>
<span style="font-weight: bold; color: #856404;"><b>ActivaciÃ³n:</b></span> Se ejecuta <b>sin</b> argumento de Project_ID. Como tutorial para el modo local hemos replicado este mÃ©todo partiendo de muestras fastq descargadas (<b>ver secciÃ³n en este GitHub en carpeta Modo local</b>).
</div>

### $\color{#2E8B57}{\text{Flujo Completo (End-to-End Processing):}}$
- **ConfiguraciÃ³n:** `"fastq_list_strategy": "manual" + Manifiesto de archivos.`.
- **DescripciÃ³n:** Procesa archivos FASTQ alojados en el sistema de ficheros local. Utiliza un manifiesto de rutas (URI file://) para ingerir las muestras y ejecutar el alineamiento y conteo.

### $\color{#2E8B57}{\text{Flujo Acelerado Local (Direct Matrix Analysis - Local):}}$
- **ConfiguraciÃ³n:** `"counting_method": "precomputed_csv" + Ruta local al archivo.`.
- **DescripciÃ³n:** Ingesta directa de una matriz de conteos (.csv) suministrada externamente o pre-calculada.

**Sintaxis (Bash):**
```bash
sbatch RNA_SEQ_LETS_TRY.sh JSON/config.json
```
</details> 

---

> [!IMPORTANT] **ğŸ›¡ï¸ Resiliencia AutomÃ¡tica & Fault Tolerance**  
> Gracias a su arquitectura modular, OmniRNA-seq es capaz de retomar ejecuciones interrumpidas. Si un job es cancelado por el clÃºster (ej. Walltime Limit), basta con re-lanzar el comando original; el sistema detectarÃ¡ los pasos completados y saltarÃ¡ directamente a la etapa pendiente.
